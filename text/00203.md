## Согласованность, параллельная обработка, параллельное выполнение  (Concurrency)

### Распределение памяти по сообщениям (Share by communicating)

Параллельное программирование является большой темой и здесь будет рассматриваться только специфичное для языка Go.


Параллельное программирование во многих средах затруднено для корректной реализации доступа к общим переменным.

В языке Go поддерживается другой подход, в котором общие переменные *shared values* передаются через каналы, по сути, никогда активно не распределяется по исполняемым потокам.
Только одна го-рутина(**goroutine**) имеет доступ к переменной в любой момент.
Перенос данных не происходит по конструкции языка.
Для того чтобы способствовать данному стилю мышления используется лозунг:


> Do not communicate by sharing memory; instead, share memory by communicating.

> Не общайтесь с распределением памяти; Вместо того чтобы распределять память по коммуникациям.


Это дальновидный подход. К примеру, наилучшим образом подсчет ссылок можно производить установкой мютексов(**mutex**) вокруг целого переменной.
Но это высокоуровневый подход, использование каналов для контроля доступа является более простым и корректным для программ.


Один из способов думать об этой модели как для типичных однопоточных программ запущенных на одном процессоре CPU. И нет необходимости в синхронизации примитивов.
Для запуска следующего экземпляра, нет необходимости в синхронизации. Сейчас рассмотрим два способа коммуникации; Если коммуникация синхронна, то все также не требуется дополнительной синхронизации. К примеру, *Unix pipelines* великолепно используют эту модель. Хотя подход языка Go для организации параллельных процессов берет начало в **Hoare's Communicating Sequential Processes (CSP)**, он также может рассматриваться как обобщение безопасности типов Unix pipes.


### Го-рутины (Goroutines)


Они называются Го-рутины, потому что существующие термины потоки, корутины, процессы и так далее передают неточную коннотацию.
**Го-рутины** имеют простую модель: это функция выполняющаяся параллельно с другими го-рутинами в одном адресном пространстве. Они легковесны стоящие чуть больше чем выделение пространства в стэке. Они дешевы, и растут по мере необходимости путем выделения или освобождения в куче.

Горутины распределяются на несколько потоков OS, и если один заблокируются, например из-за ожидания I/O, другие продолжат работу. Их дизайн скрывает много сложностей по создание потоков и их управлению.


Префикс `go` у функции или метода запускает новую горутину.
Когда вызов закончен, горутина выходит, молча. (Этот эффект похож на команду Unix с нотацией `&` означающая запуск команды в фоновом режиме.)

```go
go list.Sort()  // run list.Sort concurrently; don't wait for it.
```

Встроенные функции могут быть удобны для вызова горутин.

```go
func Announce(message string, delay time.Duration) {
    go func() {
        time.Sleep(delay)
        fmt.Println(message)
    }()  // Note the parentheses - must call the function.
}
```

В языке Go, встроенные функции закрываемые и их реализация гарантирует что ссылаемые переменные будут жить до тех пор пока функция активна.

Эти примеры не очень практичны, так как функции не имеют сигнализировать о своем завершении. Для этого у нас есть каналы.

### Каналы (Channels)

Каналы, как и карты(map) выделяются в памяти с помощью `make` и полученное значение является ссылкой на изначальную структуру данных.
Если задан необязательный целый параметр, то он указывает на размер буфера в канале.
По умолчанию, значение нулевое, как для небуферезованного или синхронного канала.

```go
ci := make(chan int)            // unbuffered channel of integers
cj := make(chan int, 0)         // unbuffered channel of integers
cs := make(chan *os.File, 100)  // buffered channel of pointers to Files
```

Небуферезованные каналы гарантируют, что обмен значениями будет синхронным между двумя горутинами в известном состоянии.


Есть много хороших идиом использования каналов. Вот один с которого мы начнем.
В предыдущем разделе мы запускали сортировку в фоне. Канал может помочь отследить завершение горутины с сортировкой.

```go
c := make(chan int)  // Allocate a channel.
// Start the sort in a goroutine; when it completes, signal on the channel.
go func() {
    list.Sort()
    c <- 1  // Send a signal; value does not matter.
}()
doSomethingForAWhile()
<-c   // Wait for sort to finish; discard sent value.
```

Получатель всегда блокируется до тех пор пока данные не получит получатель.
Если канал не буферизованный, отсылающий блокируется до тех пор пока получатель не получит данные.
Если канал буферизованный, то отсылающий блокируется только тогда когда значение копируется в буфер; если буфер полон, то будет ожидать до тех пор пока получатель не получит значение.

**TODO**
A buffered channel can be used like a semaphore, for instance to
limit throughput.  In this example, incoming requests are passed
to `handle`, which sends a value into the channel, processes
the request, and then receives a value from the channel
to ready the "semaphore" for the next consumer.
The capacity of the channel buffer limits the number of
simultaneous calls to `process`.
**-**

```go
var sem = make(chan int, MaxOutstanding)

func handle(r *Request) {
    sem <- 1    // Wait for active queue to drain.
    process(r)  // May take a long time.
    <-sem       // Done; enable next request to run.
}

func Serve(queue chan *Request) {
    for {
        req := <-queue
        go handle(req)  // Don't wait for handle to finish.
    }
}
```

**TODO**
Once `MaxOutstanding` handlers are executing `process`,
any more will block trying to send into the filled channel buffer,
until one of the existing handlers finishes and receives from the buffer.
**-**


Данный дизайн имеет проблемы: `Serve`  создает новую горутину для каждого входящего запроса, при этом будет запущено не более `MaxOutstanding` в один момент.
Если количество запросов увеличивается слишком быстро, то как результат, программа может потребовать бесконечное количество ресурсов.
Мы можем решить это изменением `Serve` используя изменения количества порождаемых горутин.
Вот очевидное решение, но будьте осторожны, так как оно имеет ошибку, которую позже исправим:

```go
func Serve(queue chan *Request) {
    for req := range queue {
        sem <- 1
        go func() {
            process(req) // Buggy; see explanation below.
            <-sem
        }()
    }
}
```

Ошибка в том, что в языке Go цикл `for`, цикл переменной повторно используется для каждой итерации, так что переменные `req` разделяется по всем горутинам.
Это не то что мы хотим.
Нам нужно убедиться, что `req` является уникальной для каждой горутиной.
Вот один из способов, передавать значение `req` как в качестве аргумента для закрытии горутины:

```go
func Serve(queue chan *Request) {
    for req := range queue {
        sem <- 1
        go func(req *Request) {
            process(req)
            <-sem
        }(req)
    }
}
```

Сравнивая эту версию с предыдущей можно увидеть разницу в том как объявляется запуск и закрытие.
Другое решение заключается в том что создается новая переменная с тем же именем, как в примере:

```go
func Serve(queue chan *Request) {
    for req := range queue {
        req := req // Create new instance of req for the goroutine.
        sem <- 1
        go func() {
            process(req)
            <-sem
        }()
    }
}
```

Может кажется странным, писать:

```go
req := req
```

Но это допустимо и идиоматично делать это.
Вы получаете новую переменную с тем же именем, намеренно затеняя переменную цикла локально, но уникальный для каждой горутины.

Возвращаясь к общей проблеме написания сервера, иной подход для управления ресурсами начинается с фиксации числа обработчиков `handle` горутин читающих из канала запросов.
Ограничение количества горутин количеством одновременных вызовов к `process`.

Функция `Serve` также принимает канал, на который посылается об окончании; после запуска горутины блокируют получающих в этот канал.


```go
func handle(queue chan *Request) {
    for r := range queue {
        process(r)
    }
}

func Serve(clientRequests chan *Request, quit chan bool) {
    // Start handlers
    for i := 0; i < MaxOutstanding; i++ {
        go handle(clientRequests)
    }
    <-quit  // Wait to be told to exit.
}
```

### Канал каналов (Channels of channels)

Одно из важных свойств Go в том что каналы это переменная, а значит аллоцированы и могут передаваться как любой другой элемент. Одно из использований данной свойства в реализации безопасного и **параллельного демультиплексирования**.

В примере из предыдущего раздела, `handle` был идеальным обработчиком для запросов, но он не определял тип обработки. Если тип включен в канал, на который отвечать, то каждый клиент может предоставить собственный путь для ответа. Вот схематичное определение типа `Request`.

```go
type Request struct {
    args        []int
    f           func([]int) int
    resultChan  chan int
}
```

Клиент предоставляет функцию и ее аргументы, а также канал внутри объекта запроса, не который будет получен ответ.

```go
func sum(a []int) (s int) {
    for _, v := range a {
        s += v
    }
    return
}

request := &Request{[]int{3, 4, 5}, sum, make(chan int)}
// Send request
clientRequests <- request
// Wait for response.
fmt.Printf("answer: %d\n", <-request.resultChan)
```

На стороне сервера, функция обработчик это единственное что меняется.

```go
func handle(queue chan *Request) {
    for req := range queue {
        req.resultChan <- req.f(req.args)
    }
}
```

Этот пример является примером основой для ограничения скорости, параллелизма, неблокирующей RPC системы и без использования мютекса.


### Параллелизм (Parallelization)

Другой пример использования этих идей в расчёте на нескольких ядрах CPU. Если расчет можно разбить на кусочки выполняющиеся независимо, то это можно распараллелить с каналами сигнализирующие, когда отдельный кусочек закончил свою работу.

К примеру, у нас есть дорогая операция выполнения на уроке элементов и эти операции могут выполнять независимо, то вот идеализированный пример.

```go
type Vector []float64

// Apply the operation to v[i], v[i+1] ... up to v[n-1].
func (v Vector) DoSome(i, n int, u Vector, c chan int) {
    for ; i < n; i++ {
        v[i] += u.Op(v[i])
    }
    c <- 1    // signal that this piece is done
}
```

Вы выполняем кусочки независимо в цикле, по одному CPU на кусочек.
Они могут закончить в любом порядке, но это не важно; мы только считаем количество сигналов окончания по каналу после запуска всех горутин.

```go
const numCPU = 4 // number of CPU cores

func (v Vector) DoAll(u Vector) {
    c := make(chan int, numCPU)  // Buffering optional but sensible.
    for i := 0; i < numCPU; i++ {
        go v.DoSome(i*len(v)/numCPU, (i+1)*len(v)/numCPU, u, c)
    }
    // Drain the channel.
    for i := 0; i < numCPU; i++ {
        <-c    // wait for one task to complete
    }
    // All done.
}
```

Вместо того, чтобы создать постоянное значение для numCPU, мы можем задать во время выполнения необходимое значение.
Функция [runtime.NumCPU](https://golang.org/pkg/runtime/#NumCPU) возвращает количество ядер CPU в машине, тогда мы должны записать:

```go
var numCPU = runtime.NumCPU()
```

Есть также такая функция [runtime.GOMAXPROCS](https://golang.org/pkg/runtime/#GOMAXPROCS), которая возвращает заданное пользователем количество ядер, которая программа Go может использовать.
По умолчанию значение `runtime.NumCPU`, но может быть переопределен путем установки в среде с тем же именем или вызовом функции с положительным числом.
Вызов с нулевым значением запрашивает значение.
Поэтому если мы хотим выполнить запрос ресурсов пользователя, мы должны написать

```go
var numCPU = runtime.GOMAXPROCS(0)
```

Будьте уверены, чтобы не путать идеи параллельно-структурированной(**concurrency—structuring**) программы как независимо исполняемых компонентов и параллельно-выполняемые вычисления(**parallelism—executing**) для эффективности на нескольких процессорах.
Хотя особенности *concurrency* в языке Go могут решить некоторые проблемы легко с использованием структур параллельного вычисления, Go является *concurrent* языком, не параллельным и не все проблемы параллелизма подходят модели Go.
Для обсуждения различий, смотрите [следующий блог](https://blog.golang.org/concurrency-is-not-parallelism).


### Текущий буфер (A leaky buffer)

Инструменты конкарентси программирования позволяют для неконкаренси идей быть нагляднее. Вот пример из пакета RPC.  Цикл клиента горутины принимает данные из нескольких источников, возможно из сети. Для того чтобы избежать выделения и освобождения буферов, он пустой список и использует буферизованный канал для его представления. Если канал пуст, то выделяется новый буфер. После того, как буфер готов, он высылает на сервер на `serverChan`.

```go
var freeList = make(chan *Buffer, 100)
var serverChan = make(chan *Buffer)

func client() {
    for {
        var b *Buffer
        // Grab a buffer if available; allocate if not.
        select {
        case b = <-freeList:
            // Got one; nothing more to do.
        default:
            // None free, so allocate a new one.
            b = new(Buffer)
        }
        load(b)              // Read next message from the net.
        serverChan <- b      // Send to server.
    }
}
```

Цикл сервера принимает каждое сообщение из клиента, обрабатывает его и возвращает буфер на пустое список.

```go
func server() {
    for {
        b := <-serverChan    // Wait for work.
        process(b)
        // Reuse buffer if there's room.
        select {
        case freeList <- b:
            // Buffer on free list; nothing more to do.
        default:
            // Free list full, just carry on.
        }
    }
}
```

Клиент пытается получить буфер из `freeList`; если ни один не доступен, он выделяется новые.
Посылка от сервера в `freeList` подставляется назад `b` в свободный список, если список не полон, и в этом случаи буфер сбрасывается, чтобы утилизироваться сборщиком мусора.

(Положение `default` в `select` выполняется когда другие условия не готовы, это означает что  `selects` никогда не блокируется.)
Эта реализация устроена как утекающее ведро со свободным списком всего в несколько строк, опираясь на буферизованный канал и сборщик мусора.
